# begin_ML
   # Toxic Comment Classifier
              # -- Siddhant Srivastava Sir
   
Problem Description:
Here provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:

1. toxic
2. severe_toxic
3. obscene
4. threat
5. insult
6. identity_hate

You must create a model which predicts a probability of each type of toxicity for each comment.

Solution Code with Output : 
https://www.kaggle.com/bcs013/simple-stepwise-solution


Note: Hyperparameter Tuning i.e. 23rd script is commented because of laptop problem. It is taking a reasonable amount of time and showing memory error sometime so for now I commented that script.
