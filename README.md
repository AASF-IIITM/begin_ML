# begin_ML
   # Toxic Comment Classifier
              # -- Siddhant Srivastava Sir
   
Problem Description:
Here provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:

1. toxic
2. severe_toxic
3. obscene
4. threat
5. insult
6. identity_hate

You must create a model which predicts a probability of each type of toxicity for each comment.

Solution Code on Online Kernel : 
https://www.kaggle.com/bcs013/simple-stepwise-solution


